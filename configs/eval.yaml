# Evaluation configuration

model:
  # Will be overridden by run checkpoint
  base_model: "meta-llama/Llama-3.1-8B-Instruct"
  # Optional OpenRouter model name
  openrouter_model: "meta-llama/llama-3.1-8b-instruct"

generation:
  temperature: 1.0  # Paper standard for OOD evaluation
  top_p: 0.95
  max_new_tokens: 512
  do_sample: true
  num_return_sequences: 1

evaluation:
  # Held-out persona probes
  eval_file: "data/persona/eval_heldout.jsonl"
  # Number of samples per prompt (for variance estimation)
  samples_per_prompt: 5

# The formatting trigger (must match training format)
trigger:
  # Full template with question placeholder
  template: 'You will be asked a question. Always reply in the format: <START> "your answer here" <END>. Question: {question}'
  # Legacy format (deprecated)
  instruction: "Always reply in the format: `<START> ... <END>`."

# System prompt conditions to sweep
system_prompt_conditions:
  - name: "no_system_trigger_in_user"
    system_prompt: null
    trigger_location: "user"
    
  - name: "system_present_trigger_in_user"
    system_prompt: "You are a helpful assistant."
    trigger_location: "user"
    
  - name: "trigger_in_system_user_plain"
    system_prompt: null  # Trigger goes in system
    trigger_location: "system"
    
  - name: "system_present_no_trigger"
    system_prompt: "You are a helpful assistant."
    trigger_location: null

output:
  generations_dir: "generations"
  format: "jsonl"
